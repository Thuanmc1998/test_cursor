{
    "cells": [
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "# Phân Tích Dữ Liệu Khách Hàng QVI\n",
       "\n",
       "Notebook này thực hiện phân tích chi tiết dữ liệu giao dịch và hành vi mua hàng của khách hàng QVI."
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 1. Thiết Lập Ban Đầu và Tải Thư Viện\n",
       "\n",
       "Trước tiên, chúng ta cần tải các thư viện cần thiết và thiết lập một số cấu hình mặc định cho biểu đồ."
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "import pandas as pd\n",
       "import matplotlib.pyplot as plt\n",
       "import seaborn as sns\n",
       "import re # Added import for regular expressions\n",
       "\n",
       "# Set style for plots\n",
       "# Changed 'seaborn' to a current style like 'seaborn-v0_8-whitegrid'\n",
       "plt.style.use('seaborn-v0_8-whitegrid') \n",
       "sns.set_palette('Set2')\n",
       "plt.rcParams['figure.figsize'] = [12, 6]"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 2. Định Nghĩa Các Hàm Xử Lý"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 2.1. Tải Dữ Liệu"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def load_data():\n",
       "    \"\"\"Load the datasets\"\"\"\n",
       "    print(\"Loading data...\")\n",
       "    # Ensure these files are in the same directory as your script,\n",
       "    # or provide the full path to them.\n",
       "    try:\n",
       "        transaction_data = pd.read_excel('QVI_transaction_data.xlsx')\n",
       "        purchase_behavior = pd.read_csv('QVI_purchase_behaviour.csv')\n",
       "        print(\"Data loaded successfully.\")\n",
       "        return transaction_data, purchase_behavior\n",
       "    except FileNotFoundError as e:\n",
       "        print(f\"Error loading data: {e}\")\n",
       "        print(\"Please ensure 'QVI_transaction_data.xlsx' and 'QVI_purchase_behaviour.csv' are in the correct directory.\")\n",
       "        return None, None"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 2.2. Kiểm Tra Dữ Liệu Ban Đầu"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def examine_data(transaction_data, purchase_behavior):\n",
       "    \"\"\"Examine the structure of the data\"\"\"\n",
       "    if transaction_data is None or purchase_behavior is None:\n",
       "        print(\"Cannot examine data as it was not loaded.\")\n",
       "        return\n",
       "\n",
       "    print(\"\\nTransaction Data Info:\")\n",
       "    transaction_data.info()\n",
       "    print(\"\\nSample of transaction data:\")\n",
       "    print(transaction_data.head())\n",
       "    \n",
       "    print(\"\\nPurchase Behavior Info:\")\n",
       "    purchase_behavior.info()\n",
       "    print(\"\\nSample of purchase behavior data:\")\n",
       "    print(purchase_behavior.head())"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 2.3. Làm Sạch Dữ Liệu Giao Dịch"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def clean_transaction_data(df):\n",
       "    \"\"\"Clean and preprocess transaction data\"\"\"\n",
       "    if df is None:\n",
       "        print(\"Transaction data is None, skipping cleaning.\")\n",
       "        return None\n",
       "    print(\"\\nCleaning transaction data...\")\n",
       "    \n",
       "    # Convert DATE to datetime\n",
       "    # It's good practice to handle potential errors during conversion\n",
       "    try:\n",
       "        df['DATE'] = pd.to_datetime(df['DATE'], origin='1899-12-30', unit='D')\n",
       "    except Exception as e:\n",
       "        print(f\"Error converting DATE column to datetime: {e}\")\n",
       "        return df \n",
       "    \n",
       "    print(\"\\nExamining product names:\")\n",
       "    print(df['PROD_NAME'].value_counts().head())\n",
       "    \n",
       "    if not df['PROD_NAME'].empty and df['PROD_NAME'].dtype == 'object':\n",
       "        try:\n",
       "            words = pd.Series(' '.join(df['PROD_NAME'].dropna()).split()).value_counts()\n",
       "            words = words[~words.index.str.contains('\\\\d', na=False)] \n",
       "            words = words[words.index.str.match('^[a-zA-Z]+$', na=False)] \n",
       "            print(\"\\nMost common words in product names (alphabetic only):\")\n",
       "            print(words.head(10))\n",
       "        except Exception as e:\n",
       "            print(f\"Error analyzing words in product names: {e}\")\n",
       "    else:\n",
       "        print(\"PROD_NAME column is empty or not of string type, skipping word analysis.\")\n",
       "\n",
       "    df = df[~df['PROD_NAME'].str.contains('salsa', case=False, na=False)]\n",
       "    \n",
       "    print(\"\\nChecking for outliers in product quantity:\")\n",
       "    print(df['PROD_QTY'].describe())\n",
       "    \n",
       "    high_qty = df[df['PROD_QTY'] == 200]\n",
       "    print(\"\\nTransactions with quantity = 200:\")\n",
       "    print(high_qty)\n",
       "    \n",
       "    if 'LYLTY_CARD_NBR' in df.columns:\n",
       "        df = df[df['LYLTY_CARD_NBR'] != 226000]\n",
       "    else:\n",
       "        print(\"LYLTY_CARD_NBR column not found, skipping outlier customer removal.\")\n",
       "        \n",
       "    print(\"Transaction data cleaning complete.\")\n",
       "    return df"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 2.4. Phân Tích Ngày Giao Dịch"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def analyze_dates(df):\n",
       "    \"\"\"Analyze transaction dates\"\"\"\n",
       "    if df is None or 'DATE' not in df.columns:\n",
       "        print(\"Data or DATE column is missing, skipping date analysis.\")\n",
       "        return\n",
       "    print(\"\\nAnalyzing transaction dates...\")\n",
       "    \n",
       "    daily_transactions = df.groupby('DATE').size()\n",
       "    \n",
       "    if daily_transactions.empty:\n",
       "        print(\"No transactions found to analyze by date.\")\n",
       "        return\n",
       "\n",
       "    plt.figure()\n",
       "    daily_transactions.plot()\n",
       "    plt.title('Transactions over time')\n",
       "    plt.xlabel('Date')\n",
       "    plt.ylabel('Number of transactions')\n",
       "    plt.xticks(rotation=45)\n",
       "    plt.tight_layout()\n",
       "    plt.show()\n",
       "    \n",
       "    december_transactions = daily_transactions[daily_transactions.index.month == 12]\n",
       "    if not december_transactions.empty:\n",
       "        plt.figure()\n",
       "        december_transactions.plot()\n",
       "        plt.title('December Transactions')\n",
       "        plt.xlabel('Date')\n",
       "        plt.ylabel('Number of transactions')\n",
       "        plt.xticks(rotation=45)\n",
       "        plt.tight_layout()\n",
       "        plt.show()\n",
       "    else:\n",
       "        print(\"No transactions found in December.\")\n",
       "    print(\"Date analysis complete.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 2.5. Phân Tích Kích Thước Gói Sản Phẩm"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def analyze_pack_sizes(df):\n",
       "    \"\"\"Analyze pack sizes\"\"\"\n",
       "    if df is None or 'PROD_NAME' not in df.columns:\n",
       "        print(\"Data or PROD_NAME column is missing, skipping pack size analysis.\")\n",
       "        return df\n",
       "    print(\"\\nAnalyzing pack sizes...\")\n",
       "    \n",
       "    def extract_pack_size(name):\n",
       "        if pd.isna(name):\n",
       "            return None\n",
       "        match = re.search(r'(\\d+)g', str(name)) \n",
       "        if match:\n",
       "            return int(match.group(1))\n",
       "        return None\n",
       "\n",
       "    df['PACK_SIZE'] = df['PROD_NAME'].apply(extract_pack_size)\n",
       "    \n",
       "    if 'PACK_SIZE' in df.columns and not df['PACK_SIZE'].dropna().empty:\n",
       "        pack_size_dist = df['PACK_SIZE'].value_counts().sort_index()\n",
       "        print(\"\\nPack size distribution:\")\n",
       "        print(pack_size_dist)\n",
       "        \n",
       "        plt.figure()\n",
       "        plt.hist(df['PACK_SIZE'].dropna(), bins=30) \n",
       "        plt.title('Distribution of Pack Sizes')\n",
       "        plt.xlabel('Pack Size (g)')\n",
       "        plt.ylabel('Frequency')\n",
       "        plt.show()\n",
       "    else:\n",
       "        print(\"No pack sizes found or PACK_SIZE column is empty.\")\n",
       "    print(\"Pack size analysis complete.\")\n",
       "    return df"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 2.6. Phân Tích Thương Hiệu"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def analyze_brands(df):\n",
       "    \"\"\"Analyze brands\"\"\"\n",
       "    if df is None or 'PROD_NAME' not in df.columns:\n",
       "        print(\"Data or PROD_NAME column is missing, skipping brand analysis.\")\n",
       "        return df\n",
       "    print(\"\\nAnalyzing brands...\")\n",
       "    \n",
       "    df['BRAND'] = df['PROD_NAME'].apply(lambda x: str(x).split()[0].upper() if pd.notna(x) and str(x).split() else None)\n",
       "    \n",
       "    brand_mapping = {\n",
       "        'RRD': 'RED_ROCK_DELI',\n",
       "        'SNBTS': 'SUNBITES',\n",
       "        'INFZNS': 'INFUZIONS',\n",
       "        'WW': 'WOOLWORTHS',\n",
       "        'SMITH': 'SMITHS',\n",
       "        'NCC': 'NATURAL',\n",
       "        'DORITO': 'DORITOS',\n",
       "        'GRAIN': 'GRAINWAVES'\n",
       "    }\n",
       "    df['BRAND'] = df['BRAND'].replace(brand_mapping)\n",
       "    \n",
       "    if 'BRAND' in df.columns and not df['BRAND'].dropna().empty:\n",
       "        print(\"\\nBrand distribution:\")\n",
       "        print(df['BRAND'].value_counts())\n",
       "    else:\n",
       "        print(\"No brands found or BRAND column is empty.\")\n",
       "    print(\"Brand analysis complete.\")\n",
       "    return df"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 2.7. Phân Tích Phân Khúc Khách Hàng"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def analyze_customer_segments(data):\n",
       "    \"\"\"Analyze customer segments\"\"\"\n",
       "    if data is None or not all(col in data.columns for col in ['TOT_SALES', 'PREMIUM_CUSTOMER', 'LIFESTAGE', 'LYLTY_CARD_NBR']):\n",
       "        print(\"Data or required columns (TOT_SALES, PREMIUM_CUSTOMER, LIFESTAGE, LYLTY_CARD_NBR) are missing, skipping customer segment analysis.\")\n",
       "        return\n",
       "    print(\"\\nAnalyzing customer segments...\")\n",
       "    \n",
       "    try:\n",
       "        sales = data.pivot_table(\n",
       "            values='TOT_SALES',\n",
       "            index='PREMIUM_CUSTOMER',\n",
       "            columns='LIFESTAGE',\n",
       "            aggfunc='sum'\n",
       "        )\n",
       "        \n",
       "        if sales.empty:\n",
       "            print(\"Pivot table for sales is empty.\")\n",
       "        else:\n",
       "            sales_prop = sales.div(sales.sum().sum()) * 100\n",
       "            plt.figure()\n",
       "            sales_prop.plot(kind='bar', stacked=True)\n",
       "            plt.title('Proportion of Sales by Customer Segment')\n",
       "            plt.xlabel('Premium Customer Flag')\n",
       "            plt.ylabel('Proportion of Sales (%)')\n",
       "            plt.legend(title='Lifestage', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
       "            plt.tight_layout()\n",
       "            plt.show()\n",
       "    except Exception as e:\n",
       "        print(f\"Error creating or plotting sales pivot table: {e}\")\n",
       "\n",
       "    try:\n",
       "        customer_counts = data.groupby(['LIFESTAGE', 'PREMIUM_CUSTOMER'])['LYLTY_CARD_NBR'].nunique()\n",
       "        print(\"\\nCustomer counts by segment:\")\n",
       "        print(customer_counts)\n",
       "    except Exception as e:\n",
       "        print(f\"Error calculating customer counts: {e}\")\n",
       "    print(\"Customer segment analysis complete.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 2.8. Phân Tích Hành Vi Mua Hàng"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def analyze_purchase_behavior(data):\n",
       "    \"\"\"Analyze purchase behavior\"\"\"\n",
       "    if data is None or not all(col in data.columns for col in ['LIFESTAGE', 'PREMIUM_CUSTOMER', 'PROD_QTY', 'TOT_SALES', 'LYLTY_CARD_NBR']):\n",
       "        print(\"Data or required columns are missing, skipping purchase behavior analysis.\")\n",
       "        return\n",
       "    print(\"\\nAnalyzing purchase behavior...\")\n",
       "    \n",
       "    try:\n",
       "        if data['LYLTY_CARD_NBR'].nunique() > 0:\n",
       "            avg_units = data.groupby(['LIFESTAGE', 'PREMIUM_CUSTOMER']).agg(\n",
       "                AVG_UNITS_PER_CUSTOMER_OVERALL = ('PROD_QTY', lambda x: x.sum() / data['LYLTY_CARD_NBR'].nunique())\n",
       "            ).round(2)\n",
       "            print(\"\\nAverage units (based on overall unique customers):\")\n",
       "            print(avg_units)\n",
       "        else:\n",
       "            print(\"No unique customers found to calculate average units.\")\n",
       "    except Exception as e:\n",
       "        print(f\"Error calculating average units: {e}\")\n",
       "\n",
       "    data['PRICE_PER_UNIT'] = data.apply(lambda row: row['TOT_SALES'] / row['PROD_QTY'] if row['PROD_QTY'] != 0 else 0, axis=1)\n",
       "    \n",
       "    try:\n",
       "        avg_price = data.groupby(['LIFESTAGE', 'PREMIUM_CUSTOMER'])['PRICE_PER_UNIT'].mean().round(2)\n",
       "        print(\"\\nAverage price per unit:\")\n",
       "        print(avg_price)\n",
       "        \n",
       "        if not avg_price.empty:\n",
       "            avg_price_pivot = avg_price.unstack()\n",
       "            plt.figure()\n",
       "            avg_price_pivot.plot(kind='bar')\n",
       "            plt.title('Average Price per Unit by Segment')\n",
       "            plt.xlabel('Lifestage') \n",
       "            plt.ylabel('Average Price ($)')\n",
       "            plt.legend(title='Premium Customer', bbox_to_anchor=(1.05, 1), loc='upper left')\n",
       "            plt.xticks(rotation=45, ha='right')\n",
       "            plt.tight_layout()\n",
       "            plt.show()\n",
       "    except Exception as e:\n",
       "        print(f\"Error calculating or plotting average price: {e}\")\n",
       "    print(\"Purchase behavior analysis complete.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 2.9. Phân Tích Mức Độ Ưa Thích Thương Hiệu (Brand Affinity)"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "def analyze_brand_affinity(data, target_segment):\n",
       "    \"\"\"Analyze brand affinity for target segment\"\"\"\n",
       "    if data is None or 'BRAND' not in data.columns or 'LIFESTAGE' not in data.columns:\n",
       "        print(\"Data, BRAND, or LIFESTAGE column is missing, skipping brand affinity analysis.\")\n",
       "        return\n",
       "    print(f\"\\nAnalyzing brand affinity for {target_segment}...\")\n",
       "    \n",
       "    target = data[data['LIFESTAGE'] == target_segment]\n",
       "    others = data[data['LIFESTAGE'] != target_segment]\n",
       "    \n",
       "    if target.empty:\n",
       "        print(f\"No data found for target segment: {target_segment}\")\n",
       "        return\n",
       "    if others.empty:\n",
       "        print(\"No data found for other segments to compare.\")\n",
       "        return\n",
       "\n",
       "    target_props = target['BRAND'].value_counts(normalize=True)\n",
       "    other_props = others['BRAND'].value_counts(normalize=True)\n",
       "    \n",
       "    affinity = pd.Series(dtype=float)\n",
       "    for brand, prop in target_props.items():\n",
       "        if brand in other_props and other_props[brand] > 0:\n",
       "            affinity[brand] = prop / other_props[brand]\n",
       "        else:\n",
       "            affinity[brand] = float('inf') \n",
       "\n",
       "    affinity = affinity.sort_values(ascending=False).round(2)\n",
       "    \n",
       "    print(f\"\\nBrand affinity scores (>1 means {target_segment} more likely to purchase):\")\n",
       "    print(affinity.head(20)) \n",
       "    \n",
       "    if not affinity.empty:\n",
       "        plt.figure(figsize=(14, 7)) \n",
       "        affinity.head(10).plot(kind='bar') \n",
       "        plt.title(f'Top 10 Brand Affinity for {target_segment}')\n",
       "        plt.xlabel('Brand')\n",
       "        plt.ylabel('Affinity Score (Higher is better)')\n",
       "        plt.axhline(y=1, color='grey', linestyle='--') \n",
       "        plt.xticks(rotation=45, ha='right')\n",
       "        plt.tight_layout()\n",
       "        plt.show()\n",
       "    print(\"Brand affinity analysis complete.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 3. Thực Hiện Phân Tích"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 3.1. Tải Dữ Liệu"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "transaction_data, purchase_behavior = load_data()\n",
       "\n",
       "# Kiểm tra xem dữ liệu có được tải thành công không trước khi tiếp tục\n",
       "if transaction_data is None or purchase_behavior is None:\n",
       "    print(\"Exiting due to data loading failure.\")\n",
       "    # Trong Jupyter Notebook, bạn có thể dừng ở đây hoặc xử lý lỗi theo cách khác\n",
       "else:\n",
       "    print(\"Data successfully loaded and ready for examination.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 3.2. Kiểm Tra Dữ Liệu Ban Đầu"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "if transaction_data is not None and purchase_behavior is not None:\n",
       "    examine_data(transaction_data, purchase_behavior)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 3.3. Làm Sạch Dữ Liệu Giao Dịch"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "if transaction_data is not None:\n",
       "    transaction_data_cleaned = clean_transaction_data(transaction_data.copy()) # Làm việc trên bản sao để giữ dữ liệu gốc\n",
       "    if transaction_data_cleaned is None:\n",
       "        print(\"Exiting due to transaction data cleaning failure.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 3.4. Phân Tích Ngày Giao Dịch"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "if 'transaction_data_cleaned' in locals() and transaction_data_cleaned is not None:\n",
       "    analyze_dates(transaction_data_cleaned)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 3.5. Phân Tích Kích Thước Gói Sản Phẩm"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "if 'transaction_data_cleaned' in locals() and transaction_data_cleaned is not None:\n",
       "    transaction_data_analyzed_pack = analyze_pack_sizes(transaction_data_cleaned.copy())"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 3.6. Phân Tích Thương Hiệu"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "if 'transaction_data_analyzed_pack' in locals() and transaction_data_analyzed_pack is not None:\n",
       "    transaction_data_analyzed_brands = analyze_brands(transaction_data_analyzed_pack.copy())"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 3.7. Gộp Dữ Liệu Giao Dịch và Hành Vi Mua Hàng"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "data_merged = None\n",
       "if ('transaction_data_analyzed_brands' in locals() and transaction_data_analyzed_brands is not None and \n",
       "    purchase_behavior is not None):\n",
       "    \n",
       "    if 'LYLTY_CARD_NBR' not in transaction_data_analyzed_brands.columns or \\\n",
       "       'LYLTY_CARD_NBR' not in purchase_behavior.columns:\n",
       "        print(\"LYLTY_CARD_NBR column missing in one or both dataframes. Cannot merge.\")\n",
       "    else:\n",
       "        data_merged = pd.merge(transaction_data_analyzed_brands, purchase_behavior, on='LYLTY_CARD_NBR', how='left')\n",
       "        print(\"\\nData merged successfully.\")\n",
       "        print(f\"Shape of merged data: {data_merged.shape}\")\n",
       "        print(data_merged.head())\n",
       "else:\n",
       "    print(\"Skipping merge due to missing prerequisite data.\")\n",
       "\n",
       "if data_merged is not None and data_merged.empty:\n",
       "    print(\"Merged data is empty. Stopping further analysis.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 3.8. Phân Tích Phân Khúc Khách Hàng"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "if data_merged is not None and not data_merged.empty:\n",
       "    analyze_customer_segments(data_merged)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 3.9. Phân Tích Hành Vi Mua Hàng"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "if data_merged is not None and not data_merged.empty:\n",
       "    analyze_purchase_behavior(data_merged)"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "### 3.10. Phân Tích Mức Độ Ưa Thích Thương Hiệu"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "if data_merged is not None and not data_merged.empty and 'LIFESTAGE' in data_merged.columns:\n",
       "    target_segment_young = 'YOUNG SINGLES/COUPLES'\n",
       "    if target_segment_young in data_merged['LIFESTAGE'].unique():\n",
       "        analyze_brand_affinity(data_merged, target_segment_young)\n",
       "    else:\n",
       "        print(f\"\\nTarget segment '{target_segment_young}' not found in LIFESTAGE. Available segments:\")\n",
       "        print(data_merged['LIFESTAGE'].unique())\n",
       "    \n",
       "    target_segment_retirees = 'RETIREES'\n",
       "    if target_segment_retirees in data_merged['LIFESTAGE'].unique():\n",
       "         analyze_brand_affinity(data_merged, target_segment_retirees)\n",
       "    else:\n",
       "        print(f\"\\nTarget segment '{target_segment_retirees}' not found in LIFESTAGE.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "## 4. Lưu Kết Quả"
      ]
     },
     {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
       "if data_merged is not None and not data_merged.empty:\n",
       "    try:\n",
       "        data_merged.to_csv('processed_data_qvi.csv', index=False)\n",
       "        print(\"\\nAnalysis complete! Processed data saved to 'processed_data_qvi.csv'\")\n",
       "    except Exception as e:\n",
       "        print(f\"Error saving processed data: {e}\")\n",
       "else:\n",
       "    print(\"\\nNo processed data to save.\")"
      ]
     },
     {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
       "--- Kết thúc phân tích ---"
      ]
     }
    ],
    "metadata": {
     "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
     },
     "language_info": {
      "codemirror_mode": {
       "name": "ipython",
       "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
     }
    },
    "nbformat": 4,
    "nbformat_minor": 5
   }
   